df.describe() # выводит статичтическую информацию по таблице (средние, медиа, квантилити и др)
df.describe(include = ['object']) # выводит информацию по столбцам (top- значение моды, freq - количество сколько раз мода встречается в столбце, unique - уникальные значения) 
df['TypeName'].value_counts() # посчитать какие значения и сколько их встречается в столбце "TypeName"
company[company == company.max()] # выведет информацию из колонки company об максимальном количестве вхождений
df.sample() # случайная строка из df

from sklearn.model_selection import train_test_split 
train, test = train_test_split(df_bmw, train_size = 0.75)  # рандомно разбивает датафрейм на две выборки в соотношении как указано в train_size

train, test = train_test_split(df_bmw, random_state = 1, train_size = 0.75) # рандомно разбивает датафрейм на две выборки в соотношении как указано в train_size,
#но при повторном срабатывании сборка будет одинаковая постоянно

train['price'].hist() # строим гистограмму и видим "жирный хвост" который характеризует что есть немного но очень дорогх машин

train_sv = train.groupby('year')['price'].agg(['count','mean', 'median']) # создает сводную таблицу с параметрами 'count','mean', 'median'
####
train['price_pred_mean'] = train['price'].mean() # Находим среднее
train['err'] = train['price_pred_mean'] - train['price'] # Находим отклонение от среднего. Видно что предсказывать цену просто отталкиваясь от среднего - дурная затея
####

from sklearn.metrics import mean_absolute_percentage_error, mean_absolute_error
mean_absolute_error(train['price'],train['price_pred_median']) # считаем ошибку на треине по медиане (определяем +\- от среднего значения)
mean_absolute_percentage_error(train['price'],train['price_pred_median']) # считаем ошибку в %
####
def engine_group(x):
  if x <= 1.5:
    return '<=1.5'
  if x <= 2:
    return '<=2'
  return '>2'

train['engine_group'] = train['engineSize'].apply(engine_group) # к каждой строке применяем функцию engine_group (разбиваем на группы)
####
# Выше было сделано разбиение на группы при помощи функции но можно это сделать при помощи cut
train['engine_group2'] = pd.cut(train['engineSize'],[-float('inf'),1.5,2,float('inf')])
# -float('inf') нужно для того чтобы включить 0.0 в самый первый диапазон
####
df[df['Company'] == 'HP']['Price_euros'].max() # Проводит фильтрацию (df['Company'] == 'HP') из тех строк что соответствуют этому условию
# выбирается колонка Price_euros и в это колонке ищется max
####
df.value_counts('TypeName', normalize = True) # по колонке TypeName выводит информацию в процентном соотношении
####
df.sample() # вернет случайную строчку из df
df.sample(frac=0.5) # верент таблицу состоящая из половины таблицы df но перемешанная случайным образом
####
df.dtypes # выводит информацию по типам данных в колонках
df['age'].astype('float64') # поменять тип данных в колонке age на float64 (надо записать в отдельную колонку, так как саму колонку команда не меняет)
df['age'].unique() # возвращает все уникальные значения из колонки age
df['age'].nunique() # возвращает количество всех уникальных значений из колонки age
df['age'].value_counts() # возвращает частотность всех уникальных значений в количестве
df['age'].value_counts(normalize=True) # возвращает частотность всех уникальных значений в процентах
df.shape # верент кортеж с размерностью таблицы
df.describe() # по умолчанию возвращает статистику по числовым данным таблицы
df.describe(include = ['object']) # возвращает информацию по столбцам имещие тип данных object (можно и по bool так же сделать)

